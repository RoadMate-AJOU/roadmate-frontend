// service/mic/FloatingMicViewModel.tsx
import { useState, useRef } from 'react';
import * as Speech from 'expo-speech';
import { router, useRouter } from 'expo-router';
import {
  ExpoSpeechRecognitionModule,
  useSpeechRecognitionEvent,
} from 'expo-speech-recognition';
import { setVoiceOwner, getVoiceOwner, clearVoiceOwner } from '@/hooks/VoiceOwner';
import { gptService } from '@/services/api';
import { useSessionStore } from '@/contexts/sessionStore';
import { useRoute } from '../../model/RouteContext';
import { fetchBusArrivalTime } from '../transportTime/fetchBusArrivalTime';
import { fetchSubwayArrivalTime } from '../transportTime/fetchSubwayArrivalTime';

const ENABLE_VOICE = true;

export function useVoiceViewModel() {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const recognizedTextRef = useRef('');
  const router = useRouter();
    const { sessionId } = useSessionStore();
    const { routeData } = useRoute();

  const sendToBackend = async (text: string) => {
    try {
      const json = await gptService.askQuestion({
        sessionId,
        text,
      });

      const { status, intent, responseMessage } = json;

      if (!ENABLE_VOICE) return;

      if (responseMessage) {
        Speech.speak(responseMessage, {
              language: 'ko-KR',
              onDone: () => {
                (async () => {
                  if (status === 'API_REQUIRED') {
                    if (intent === 'real_time_bus_arrival' && data?.bus_number && routeData) {
                      const busNumber = data.bus_number;
                      const busGuide = routeData.guides.find(
                        (g) => g.transportType === 'BUS' && g.busNumber?.replace(/\s/g, '') === busNumber.replace(/\s/g, '')
                      );
                      if (busGuide && busGuide.startLocation?.name) {
                        const stopName = busGuide.startLocation.name;
                        const arrival = await fetchBusArrivalTime(stopName, busNumber);
        
                        let arrivalText = 'ë„ì°© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                        if (arrival === 'ìš´í–‰ì¢…ë£Œ') arrivalText = 'ìš´í–‰ì´ ì¢…ë£Œëœ ë²„ìŠ¤ì…ë‹ˆë‹¤.';
                        else if (arrival === 'ì¶œë°œëŒ€ê¸° ì¤‘') arrivalText = 'ì¶œë°œ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.';
                        else if (typeof arrival === 'number') {
                          arrivalText = arrival === 0 ? 'ê³§ ë„ì°©í•©ë‹ˆë‹¤.' : `${arrival}ë¶„ í›„ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤.`;
                        } else if (typeof arrival === 'string') {
                          arrivalText = arrival;
                        }
        
                        Speech.speak(`${busNumber}ë²ˆ ë²„ìŠ¤, ${stopName} ì •ë¥˜ì¥ ê¸°ì¤€ ${arrivalText}`, {
                          language: 'ko-KR',
                          onDone: () => setIsSpeaking(false),
                        });
                      } else {
                        Speech.speak('ë²„ìŠ¤ ì •ë¥˜ì¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', {
                          language: 'ko-KR',
                          onDone: () => setIsSpeaking(false),
                        });
                      }
                    } else if (intent === 'real_time_subway_arrival' && data?.subway_line && routeData) {
                      const lineName = data.subway_line;
                      const subwayGuide = routeData.guides.find(
                        (g) => g.transportType === 'SUBWAY' && g.routeName?.replace(/\s/g, '') === lineName.replace(/\s/g, '')
                      );
        
                      if (subwayGuide && subwayGuide.startLocation?.name) {
                        const stationName = subwayGuide.startLocation.name;
                        const arrivalMin = await fetchSubwayArrivalTime(stationName, lineName);
        
                        let arrivalText = 'ë„ì°© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                        if (typeof arrivalMin === 'number') {
                          arrivalText = arrivalMin === 0 ? 'ê³§ ë„ì°©í•©ë‹ˆë‹¤.' : `${arrivalMin}ë¶„ í›„ ë„ì°© ì˜ˆì •ì…ë‹ˆë‹¤.`;
                        }
        
                        Speech.speak(`${lineName}, ${stationName}ì—­ ê¸°ì¤€ ${arrivalText}`, {
                          language: 'ko-KR',
                          onDone: () => setIsSpeaking(false),
                        });
                        return;
                      }
                    } else if (['extract_route', 'research_route'].includes(intent)) {
                      Speech.speak('í™ˆìœ¼ë¡œ ì´ë™í• ê²Œìš”. ëª©ì ì§€ë¥¼ ë‹¤ì‹œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.', {
                        language: 'ko-KR',
                        onDone: () => {
                          setIsSpeaking(false);
                          router.replace('/(tabs)');
                        },
                      });
                    } else {
                      setIsSpeaking(false);
                    }
                  } else {
                    setIsSpeaking(false);
                  }
                })();
              },
              onError: () => setIsSpeaking(false),
            });
      } else {
        setIsSpeaking(false);
      }
    } catch (err) {
      console.error('âŒ gptService ì˜¤ë¥˜:', err);
      setIsSpeaking(false);
    }
  };

  const handleMicPress = async () => {
    if (!ENABLE_VOICE) {
      console.warn('âš ï¸ ìŒì„± ì¸ì‹ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      return;
    }

    if (isListening) {
      try {
        await ExpoSpeechRecognitionModule.stop();
      } catch (err) {
        console.error('âŒ ìŒì„± ì¸ì‹ ì¢…ë£Œ ì˜¤ë¥˜:', err);
      }
    } else {
      try {
        setVoiceOwner('mic');
        await ExpoSpeechRecognitionModule.start({
          lang: 'ko-KR',
          continuous: false,
          interimResults: true,
        });
        setIsListening(true);
        setIsSpeaking(true);
      } catch (err) {
        console.error('âŒ ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', err);
      }
    }
  };

  useSpeechRecognitionEvent('result', (event) => {
    const finalText = event.results?.[0]?.transcript;
    if (finalText) {
      recognizedTextRef.current = finalText;
      console.log('âœ… ìµœì¢… ì¸ì‹:', finalText);
    }
  });

  useSpeechRecognitionEvent('end', () => {
  if (getVoiceOwner() !== 'mic') return;
  setIsListening(false);
  clearVoiceOwner();

  const finalText = recognizedTextRef.current;
  if (finalText) {
    console.log('ğŸ§  ì¸ì‹ëœ í…ìŠ¤íŠ¸:', finalText);

    // âœ… ë°±ì—”ë“œë¡œ ë³´ë‚¸ ì—¬ë¶€ ì¶”ì 
    let hasSentToBackend = false;

    // âœ… ì¸ì‹ëœ ìŒì„±ì„ ë¨¼ì € TTSë¡œ ì½ê¸°
    Speech.speak(finalText, {
      language: 'ko-KR',
      onDone: () => {
        if (!hasSentToBackend) {
          console.log('âœ… TTS ì™„ë£Œ, ë°±ì—”ë“œ ì „ì†¡ ì‹œì‘');
          hasSentToBackend = true;
          sendToBackend(finalText); // âœ… ì½ì€ í›„ ë°±ì—”ë“œ ì „ì†¡
        }
      },
      onError: (err) => {
        console.error('âŒ TTS ì˜¤ë¥˜:', err);
        setIsSpeaking(false);
      },
    });

    // âœ… Fallback: onDoneì´ ë¶ˆë¦¬ì§€ ì•Šì„ ê²½ìš°ì—ë„ ì‹¤í–‰ë˜ë„ë¡
    setTimeout(() => {
      if (!hasSentToBackend) {
        console.warn('â±ï¸ TTS onDone ëˆ„ë½ â†’ fallbackìœ¼ë¡œ ë°±ì—”ë“œ ì „ì†¡');
        hasSentToBackend = true;
        sendToBackend(finalText);
      }
    }, 4000); // 3ì´ˆë³´ë‹¤ ì•½ê°„ ì—¬ìœ  ìˆê²Œ
  } else {
    console.log('âš ï¸ ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    setIsSpeaking(false);
  }
});




  useSpeechRecognitionEvent('error', (event) => {
    console.error('âŒ ìŒì„± ì¸ì‹ ì—ëŸ¬:', event.error);
    setIsListening(false);
    setIsSpeaking(false);
  });

  return {
    isSpeaking,
    isListening,
    handleMicPress,
  };
}
