import React, { useEffect, useState } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  TextInput,
  ScrollView,
  PermissionsAndroid,
  Platform,
} from 'react-native';
import {
  ExpoSpeechRecognitionModule,
  useSpeechRecognitionEvent,
} from 'expo-speech-recognition';
import { Ionicons } from '@expo/vector-icons';
import { router } from 'expo-router';

const ENABLE_VOICE = true;

export default function Home() {
  const [recognizedText, setRecognizedText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [logMessages, setLogMessages] = useState([]);

  const appendLog = (msg: string) => {
    setLogMessages((prev) => [...prev.slice(-19), msg]);
  };

  const requestAudioPermission = async () => {
    if (Platform.OS === 'android') {
      const granted = await PermissionsAndroid.request(
        PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
        {
          title: 'ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­',
          message: 'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          buttonPositive: 'í™•ì¸',
        }
      );
      return granted === PermissionsAndroid.RESULTS.GRANTED;
    }
    return true;
  };

  const startRecognizing = async () => {
    if (!ENABLE_VOICE) return;

    const granted = await requestAudioPermission();
    if (!granted) {
      appendLog('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
      return;
    }

    try {
      await ExpoSpeechRecognitionModule.start({
        lang: 'ko-KR',
        continuous: true,
        interimResults: true,
      });
      appendLog('â–¶ï¸ ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
      const perm = await ExpoSpeechRecognitionModule.getPermissionsAsync();
      appendLog(`ê¶Œí•œ ìƒíƒœ: ${JSON.stringify(perm)}`);
      setIsListening(true);
    } catch (error) {
      appendLog(`âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${JSON.stringify(error)}`);
    }
  };

  const stopRecognizing = async () => {
    try {
      await ExpoSpeechRecognitionModule.stop();
      appendLog('â¹ï¸ ìŒì„± ì¸ì‹ ì¤‘ì§€ë¨');
      setIsListening(false);
    } catch (e) {
      appendLog(`âŒ ì¤‘ì§€ ì˜¤ë¥˜: ${JSON.stringify(e)}`);
    }
  };

 useSpeechRecognitionEvent("result", (event) => {
   const transcript = event.results?.[0]?.transcript;
   if (transcript) {
     appendLog(`ğŸ—£ï¸ ì¸ì‹ ê²°ê³¼: ${transcript}`);
     setRecognizedText(transcript);
   }
 });

 useSpeechRecognitionEvent("partialresult", (event) => {
   const transcript = event.text;
   if (transcript) {
     appendLog(`ğŸ“ ì¸ì‹ ì¤‘: ${transcript}`);
     setRecognizedText(transcript);
   }
 });

 useSpeechRecognitionEvent("end", () => {
   appendLog('ğŸ”‡ ìŒì„± ì¸ì‹ ì¢…ë£Œ');
   setIsListening(false);
   router.push('/destination');
 });

 useSpeechRecognitionEvent("error", (event) => {
   appendLog(`âŒ ì¸ì‹ ì—ëŸ¬: ${event.message}`);
   setIsListening(false);
 });

  return (
    <View style={styles.container}>
      {/* ê²€ìƒ‰ì°½ */}
      <View style={styles.searchBox}>
        <TextInput
          style={styles.input}
          placeholder="ëª©ì ì§€ ê²€ìƒ‰"
          placeholderTextColor="#FF5900"
          value={recognizedText}
          onChangeText={setRecognizedText}
        />
        <Ionicons name="search" size={18} color="#FF5900" />
      </View>

      <View style={styles.guideTextContainer}>
        <Text style={styles.guideText}>ë§ˆì´í¬ë¥¼ ëˆ„ë¥´ê³  ëª©ì ì§€ë¥¼ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.</Text>
        <Text style={styles.exampleText}>ì˜ˆ) â€œì„œìš¸ì—­ê¹Œì§€ ê°€ê³  ì‹¶ì–´â€</Text>
      </View>

      {/* ë§ˆì´í¬ ë²„íŠ¼ */}
      <View style={styles.centerContent}>
        <TouchableOpacity
          style={[styles.micButton, isListening && styles.micButtonActive]}
          onPress={isListening ? stopRecognizing : startRecognizing}
        >
          <Ionicons name="mic-outline" size={100} color="white" />
        </TouchableOpacity>
      </View>

      {/* ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì‹¤ì‹œê°„ ì¶œë ¥ */}
      <View style={styles.resultContainer}>
        <Text style={styles.resultTitle}>ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸</Text>
        <Text style={styles.resultText}>
          {recognizedText || 'ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”.'}
        </Text>
      </View>

      {/* ë¡œê·¸ ì¶œë ¥ */}
      <ScrollView style={styles.logContainer}>
        {logMessages.map((msg, idx) => (
          <Text key={idx} style={styles.logText}>â€¢ {msg}</Text>
        ))}
      </ScrollView>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#fff',
    paddingTop: 50,
  },
  searchBox: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: '#FFEFE5',
    paddingHorizontal: 15,
    paddingVertical: 8,
    borderRadius: 20,
    width: '80%',
    height: '12%',
    alignSelf: 'center',
    marginBottom: 20,
  },
  input: {
    flex: 1,
    fontSize: 20,
    color: '#FF5900',
  },
  guideTextContainer: {
    marginTop: 50,
    marginBottom: 30,
    alignItems: 'center',
  },
  guideText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
    marginBottom: 4,
  },
  exampleText: {
    fontSize: 20,
    color: '#444',
    textAlign: 'center',
  },
  centerContent: {
    alignItems: 'center',
    justifyContent: 'center',
  },
  micButton: {
    backgroundColor: '#FF5900',
    width: 200,
    height: 200,
    borderRadius: 100,
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOpacity: 0.15,
    shadowRadius: 6,
    shadowOffset: { width: 0, height: 3 },
  },
  micButtonActive: {
    shadowColor: '#FF5900',
    shadowOpacity: 0.6,
    shadowRadius: 25,
    shadowOffset: { width: 0, height: 0 },
    elevation: 20,
  },
  resultContainer: {
    paddingHorizontal: 30,
    paddingTop: 40,
  },
  resultTitle: {
    fontSize: 16,
    color: '#666',
    marginBottom: 8,
  },
  resultText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
  },
  logContainer: {
    maxHeight: 150,
    paddingHorizontal: 20,
    marginTop: 30,
    marginBottom: 20,
  },
  logText: {
    fontSize: 14,
    color: '#333',
    marginBottom: 4,
  },
});
