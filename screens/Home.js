import React, { useEffect, useState } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  TextInput,
  PermissionsAndroid,
  Platform,
  Alert,
} from 'react-native';
import { Ionicons } from '@expo/vector-icons';
import { router, useLocalSearchParams } from 'expo-router';
import { useLocation } from '../contexts/LocationContext';
import { poiService, gptService } from '../services/api';
import * as Speech from 'expo-speech';
import { setVoiceOwner, getVoiceOwner, clearVoiceOwner } from '../hooks/VoiceOwner';
import { useSessionStore } from '@/contexts/sessionStore';
import { useSpeechRecognitionEvent, ExpoSpeechRecognitionModule } from 'expo-speech-recognition';

const ENABLE_VOICE = true;

export default function Home() {
  const [recognizedText, setRecognizedText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isSearching, setIsSearching] = useState(false);
  const { sessionId } = useSessionStore();

  useEffect(() => {
    Speech.speak('í™”ë©´ì— ë³´ì´ëŠ” ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ëª©ì ì§€ë¥¼ ë§í•´ë³´ì„¸ìš”.', {
      language: 'ko-KR',
      pitch: 1.0,
      rate: 1.0,
      onDone: () => {
        Speech.speak('ê²½ë¡œì™€ ê´€ë ¨í•œ ì§ˆë¬¸ë§Œ í•´ì£¼ì„¸ìš”.', {
          language: 'ko-KR',
          pitch: 1.0,
          rate: 1.0,
        });
      },
    });
  }, []);

  const requestAudioPermission = async () => {
    if (Platform.OS === 'android') {
      const granted = await PermissionsAndroid.request(
        PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
        {
          title: 'ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­',
          message: 'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          buttonPositive: 'í™•ì¸',
        }
      );
      return granted === PermissionsAndroid.RESULTS.GRANTED;
    }
    return true;
  };

  // í…ìŠ¤íŠ¸ë¡œ ëª©ì ì§€ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
  const handleTextSearch = async () => {
    const inputText = recognizedText.trim();
    if (!inputText) {
      Alert.alert('ì•Œë¦¼', 'ëª©ì ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsSearching(true);
    try {
      const res = await gptService.askQuestion(inputText);
const destination = res?.data?.destination;

console.log('ëª©ì ì§€: ',destination); // ğŸ‘‰ 'ì„œìš¸ì—­'
      if (!destination) {
        Alert.alert('ì˜¤ë¥˜', 'ëª©ì ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.');
        return;
      }

      Speech.speak(`${destination} ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. ì›í•˜ì‹œëŠ” ëª©ì ì§€ë¥¼ ëˆŒëŸ¬ ì£¼ì„¸ìš”.`, {
        language: 'ko-KR',
        pitch: 1.0,
        rate: 1.0,
      });

      await searchPOI(destination);
    } catch (error) {
      Alert.alert('í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜', 'ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsSearching(false);
    }
  };


  // ìŒì„±ìœ¼ë¡œ ëª©ì ì§€ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
  const handleVoiceSearch = async (voiceText) => {
    if (!voiceText.trim()) {
      Alert.alert('ì•Œë¦¼', 'ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsSearching(true);
    try {
      const res = await gptService.askQuestion(voiceText);
const destination = res?.data?.destination;

console.log('ëª©ì ì§€: ',destination); // ğŸ‘‰ 'ì„œìš¸ì—­'
      if (!destination) {
        Alert.alert('ì˜¤ë¥˜', 'ëª©ì ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
        return;
      }

      Speech.speak(`${destination} ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. ì›í•˜ì‹œëŠ” ëª©ì ì§€ë¥¼ ëˆŒëŸ¬ ì£¼ì„¸ìš”.`, {
        language: 'ko-KR',
        pitch: 1.0,
        rate: 1.0,
      });

      await searchPOI(destination);
    } catch (error) {
      Alert.alert('ìŒì„± ê²€ìƒ‰ ì˜¤ë¥˜', 'ìŒì„± ì¸ì‹ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsSearching(false);
    }
  };


  // gptê°€ ëª©ì ì§€ ì¶”ì¶œí•´ì„œ ì£¼ë©´ ê·¸ê±¸ë¡œ ëª©ì ì§€ ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
  const searchPOI = async (keyword) => {
    //  const currentLocation = location || { latitude: 37.2816, longitude: 127.0453 };

    // ì´ í˜„ì¬ ìœ„ì¹˜ ë°ì´í„°ëŠ” ì„œìš¸ì‹œì—ì„œ ì‹œë®¬ë ˆì´ì…˜ í•˜ê³ ì ë„£ì€ ê°’ì„ (ë°ì´ì½˜ íšŒì‚¬ ìœ„ì¹˜ì„)
    const currentLocation = { latitude: 37.52759656, longitude: 126.91994412 };

    try {
      // ëª©ì ì§€ ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰í•œ ê²°ê³¼ ë°›ì•„ì˜´
      const response = await poiService.searchPOI(
        keyword,
        currentLocation.latitude,
        currentLocation.longitude
      );

      // ê°’ desination (ì¦‰, DestinationList)ì— ë„˜ê¹€
      if (response.places && response.places.length > 0) {
        router.push({
          pathname: '/destination',
          params: {
            sessionId: sessionId,
            searchKeyword: keyword,
            poiResults: JSON.stringify(response.places),
            totalCount: response.totalCount,
          },
        });
      } else {
        Alert.alert('ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ', `${keyword}ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.`);
      }
    } catch (error) {
      throw error;
    }
  };

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const startRecognizing = async () => {
    if (!ENABLE_VOICE) {
      if (recognizedText.trim()) {
        handleTextSearch();
      } else {
        Alert.alert('ì•Œë¦¼', 'ìŒì„± ì¸ì‹ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.');
      }
      return;
    }

    const granted = await requestAudioPermission();
    if (!granted) return;

    try {
      setVoiceOwner('home');
      // ì¸ì‹ ì‹œì‘
      await ExpoSpeechRecognitionModule.start({
        lang: 'ko-KR',
        continuous: true,
        interimResults: true,
      });
      setIsListening(true);
    } catch (error) { }
  };

  // ì¸ì‹ ì¢…ë£Œ
  const stopRecognizing = async () => {
    if (!ENABLE_VOICE) return;

    try {
      await ExpoSpeechRecognitionModule.stop();
      setIsListening(false);
    } catch (e) { }
  };

   useSpeechRecognitionEvent("result", (event) => {
     if (!ENABLE_VOICE) return;
     const transcript = event.results?.[0]?.transcript;
     if (transcript) setRecognizedText(transcript);
   });
  
   useSpeechRecognitionEvent("partialresult", (event) => {
     if (!ENABLE_VOICE) return;
     const transcript = event.text;
     if (transcript) setRecognizedText(transcript);
   });
  
   useSpeechRecognitionEvent("end", () => {
     if (!ENABLE_VOICE) return;
     if (getVoiceOwner() !== 'home') return;
     setIsListening(false);
     clearVoiceOwner();
     if (recognizedText.trim()) {
       handleVoiceSearch(recognizedText);
     }
   });
  
   useSpeechRecognitionEvent("error", () => {
     if (!ENABLE_VOICE) return;
     setIsListening(false);
   });


  return (
    <View style={styles.container}>
      <View style={styles.searchBox}>
        <TextInput
          style={styles.input}
          placeholder="ëª©ì ì§€ ê²€ìƒ‰"
          placeholderTextColor="#FF5900"
          value={recognizedText}
          onChangeText={setRecognizedText}
          onSubmitEditing={handleTextSearch}
          editable={!isSearching && !isListening}
        />
        <TouchableOpacity onPress={handleTextSearch} disabled={isSearching || isListening}>
          <Ionicons name="search" size={18} color="#FF5900" />
        </TouchableOpacity>
      </View>

      <View style={styles.guideTextContainer}>
        <Text style={styles.guideText}>
          {isSearching
            ? 'ê²€ìƒ‰ ì¤‘...'
            : ENABLE_VOICE
              ? 'ë§ˆì´í¬ë¥¼ ëˆ„ë¥´ê³  ëª©ì ì§€ë¥¼ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.'
              : 'í…ìŠ¤íŠ¸ë¡œ ëª©ì ì§€ë¥¼ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.'}
        </Text>
        <Text style={styles.exampleText}>
          {ENABLE_VOICE ? 'ì˜ˆ) "ì„œìš¸ì—­ê¹Œì§€ ê°€ê³  ì‹¶ì–´"' : 'ì˜ˆ) "ì„œìš¸ì—­"'}
        </Text>
      </View>

      <View style={styles.centerContent}>
        <TouchableOpacity
          style={[
            styles.micButton,
            (isListening || isSearching) && styles.micButtonActive,
            !ENABLE_VOICE && styles.micButtonDisabled,
          ]}
          onPress={isListening ? stopRecognizing : startRecognizing}
          disabled={isSearching}
        >
          {isSearching ? (
            <Ionicons name="hourglass-outline" size={100} color="white" />
          ) : (
            <Ionicons
              name={ENABLE_VOICE ? 'mic-outline' : 'search-outline'}
              size={100}
              color="white"
            />
          )}
        </TouchableOpacity>
      </View>

      <View style={styles.resultContainer}>
        <Text style={styles.resultText}>
          {isSearching
            ? 'ê²€ìƒ‰ ì¤‘...'
            : recognizedText ||
            (ENABLE_VOICE ? 'ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”.' : 'ìœ„ ê²€ìƒ‰ì°½ì— ëª©ì ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')}
        </Text>
      </View>

      {!ENABLE_VOICE && (
        <View style={styles.warningContainer}>
          <Text style={styles.warningText}>
            âš ï¸ ìŒì„± ì¸ì‹ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.{'\n'}
            ê°œë°œ ë¹Œë“œì—ì„œ ìŒì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
          </Text>
        </View>
      )}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#fff',
    paddingTop: 50,
  },
  searchBox: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: '#FFEFE5',
    paddingHorizontal: 15,
    borderRadius: 20,
    width: '80%',
    height: 64,
    alignSelf: 'center',
    marginBottom: 20,
  },
  input: {
    flex: 1,
    fontSize: 20,
    color: '#FF5900',
  },
  guideTextContainer: {
    marginTop: 50,
    marginBottom: 30,
    alignItems: 'center',
  },
  guideText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
    marginBottom: 4,
  },
  exampleText: {
    fontSize: 20,
    color: '#444',
    textAlign: 'center',
  },
  centerContent: {
    alignItems: 'center',
    justifyContent: 'center',
  },
  micButton: {
    backgroundColor: '#FF5900',
    width: 200,
    height: 200,
    borderRadius: 100,
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOpacity: 0.4,
    shadowRadius: 6,
    shadowOffset: { width: 0, height: 3 },
  },
  micButtonActive: {
    shadowColor: '#FF5900',
    shadowOpacity: 0.9,
    shadowRadius: 40,
    shadowOffset: { width: 0, height: 0 },
    elevation: 30,
  },
  micButtonDisabled: {
    backgroundColor: '#ccc',
  },
  resultContainer: {
    paddingHorizontal: 30,
    paddingTop: 40,
  },
  resultText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
  },
  warningContainer: {
    marginHorizontal: 20,
    marginTop: 20,
    padding: 15,
    backgroundColor: '#FFF3CD',
    borderRadius: 8,
    borderLeftWidth: 4,
    borderLeftColor: '#FFC107',
  },
  warningText: {
    fontSize: 14,
    color: '#856404',
    textAlign: 'center',
  },
});
