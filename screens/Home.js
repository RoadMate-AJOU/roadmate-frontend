import React, { useEffect, useState } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  TextInput,
  ScrollView,
  PermissionsAndroid,
  Platform,
  Alert,
} from 'react-native';
import {
  ExpoSpeechRecognitionModule,
  useSpeechRecognitionEvent,
} from 'expo-speech-recognition';
import { Ionicons } from '@expo/vector-icons';
import { router } from 'expo-router';
import { useLocation } from '../contexts/LocationContext';
import { poiService, gptService } from '../services/api'; // API ì„œë¹„ìŠ¤ ì¶”ê°€

const ENABLE_VOICE = true;

export default function Home() {
  const [recognizedText, setRecognizedText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isSearching, setIsSearching] = useState(false);
  const [logMessages, setLogMessages] = useState([]);
  const { location } = useLocation();

  const appendLog = (msg) => {
    setLogMessages((prev) => [...prev.slice(-19), msg]);
    console.log('ğŸ  HOME LOG:', msg);
  };

  const requestAudioPermission = async () => {
    if (Platform.OS === 'android') {
      const granted = await PermissionsAndroid.request(
        PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
        {
          title: 'ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­',
          message: 'ìŒì„± ì¸ì‹ì„ ìœ„í•´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          buttonPositive: 'í™•ì¸',
        }
      );
      return granted === PermissionsAndroid.RESULTS.GRANTED;
    }
    return true;
  };

  // í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì²˜ë¦¬ í•¨ìˆ˜
  const handleTextSearch = async () => {
    if (!recognizedText.trim()) {
      Alert.alert('ì•Œë¦¼', 'ëª©ì ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsSearching(true);
    appendLog(`ğŸ“ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œì‘: ${recognizedText}`);

    try {
      // í…ìŠ¤íŠ¸ ì…ë ¥ì‹œ ë°”ë¡œ POI ê²€ìƒ‰
      await searchPOI(recognizedText.trim());
    } catch (error) {
      appendLog(`âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: ${error.message}`);
      Alert.alert('ê²€ìƒ‰ ì˜¤ë¥˜', 'ê²€ìƒ‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsSearching(false);
    }
  };

  // ìŒì„± ê²€ìƒ‰ ì²˜ë¦¬ í•¨ìˆ˜
  const handleVoiceSearch = async (voiceText) => {
    if (!voiceText.trim()) {
      Alert.alert('ì•Œë¦¼', 'ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      return;
    }

    setIsSearching(true);
    appendLog(`ğŸ¤ ìŒì„± ê²€ìƒ‰ ì‹œì‘: ${voiceText}`);

    try {
      // ìŒì„± ì…ë ¥ì‹œ GPTë¡œ íŒŒì‹± í›„ POI ê²€ìƒ‰
      appendLog('ğŸ¤– GPTë¡œ ìŒì„± íŒŒì‹± ì¤‘...');
      const parsedResult = await gptService.parseUserInput(voiceText);
      appendLog(`ğŸ“ íŒŒì‹± ê²°ê³¼: ${parsedResult.destination}`);

      if (!parsedResult.destination) {
        Alert.alert('ì˜¤ë¥˜', 'ëª©ì ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”.');
        return;
      }

      // íŒŒì‹±ëœ ëª©ì ì§€ë¡œ POI ê²€ìƒ‰
      await searchPOI(parsedResult.destination);
    } catch (error) {
      appendLog(`âŒ ìŒì„± ê²€ìƒ‰ ì˜¤ë¥˜: ${error.message}`);
      Alert.alert('ìŒì„± ê²€ìƒ‰ ì˜¤ë¥˜', 'ìŒì„± ì¸ì‹ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsSearching(false);
    }
  };

  // POI ê²€ìƒ‰ í•¨ìˆ˜
  const searchPOI = async (keyword) => {
    const currentLocation = location || { latitude: 37.2816, longitude: 127.0453 };

    appendLog(`ğŸ” POI ê²€ìƒ‰: ${keyword}`);
    appendLog(`ğŸ“ í˜„ì¬ ìœ„ì¹˜: ${currentLocation.latitude}, ${currentLocation.longitude}`);

    try {
      const response = await poiService.searchPOI(
        keyword,
        currentLocation.latitude,
        currentLocation.longitude
      );

      if (response.places && response.places.length > 0) {
        appendLog(`âœ… ê²€ìƒ‰ ì™„ë£Œ: ${response.places.length}ê°œ ê²°ê³¼`);

        // ê²€ìƒ‰ ê²°ê³¼ì™€ í•¨ê»˜ destination í˜ì´ì§€ë¡œ ì´ë™
        router.push({
          pathname: '/destination',
          params: {
            searchKeyword: keyword,
            poiResults: JSON.stringify(response.places),
            totalCount: response.totalCount,
          }
        });
      } else {
        appendLog('âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ');
        Alert.alert('ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ', `"${keyword}"ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.`);
      }
    } catch (error) {
      appendLog(`âŒ POI ê²€ìƒ‰ ì‹¤íŒ¨: ${error.message}`);
      throw error;
    }
  };

  const startRecognizing = async () => {
    if (!ENABLE_VOICE) {
      // ìŒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° í…ìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰
      if (recognizedText.trim()) {
        handleVoiceSearch(recognizedText);
      } else {
        Alert.alert('ì•Œë¦¼', 'ê²€ìƒ‰í•  ëª©ì ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
      }
      return;
    }

    const granted = await requestAudioPermission();
    if (!granted) {
      appendLog('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
      return;
    }

    try {
      await ExpoSpeechRecognitionModule.start({
        lang: 'ko-KR',
        continuous: true,
        interimResults: true,
      });
      appendLog('â–¶ï¸ ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
      const perm = await ExpoSpeechRecognitionModule.getPermissionsAsync();
      appendLog(`ê¶Œí•œ ìƒíƒœ: ${JSON.stringify(perm)}`);
      setIsListening(true);
    } catch (error) {
      appendLog(`âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${JSON.stringify(error)}`);
    }
  };

  const stopRecognizing = async () => {
    try {
      await ExpoSpeechRecognitionModule.stop();
      appendLog('â¹ï¸ ìŒì„± ì¸ì‹ ì¤‘ì§€ë¨');
      setIsListening(false);
    } catch (e) {
      appendLog(`âŒ ì¤‘ì§€ ì˜¤ë¥˜: ${JSON.stringify(e)}`);
    }
  };

  useSpeechRecognitionEvent("result", (event) => {
    const transcript = event.results?.[0]?.transcript;
    if (transcript) {
      appendLog(`ğŸ—£ï¸ ì¸ì‹ ê²°ê³¼: ${transcript}`);
      setRecognizedText(transcript);
    }
  });

  useSpeechRecognitionEvent("partialresult", (event) => {
    const transcript = event.text;
    if (transcript) {
      appendLog(`ğŸ“ ì¸ì‹ ì¤‘: ${transcript}`);
      setRecognizedText(transcript);
    }
  });

  useSpeechRecognitionEvent("end", () => {
    appendLog('ğŸ”‡ ìŒì„± ì¸ì‹ ì¢…ë£Œ');
    setIsListening(false);

    // ìŒì„± ì¸ì‹ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    if (recognizedText.trim()) {
      handleVoiceSearch(recognizedText);
    }
  });

  useSpeechRecognitionEvent("error", (event) => {
    appendLog(`âŒ ì¸ì‹ ì—ëŸ¬: ${event.message}`);
    setIsListening(false);
  });

  return (
    <View style={styles.container}>
      {/* ê²€ìƒ‰ì°½ */}
      <View style={styles.searchBox}>
        <TextInput
          style={styles.input}
          placeholder="ëª©ì ì§€ ê²€ìƒ‰"
          placeholderTextColor="#FF5900"
          value={recognizedText}
          onChangeText={setRecognizedText}
          onSubmitEditing={handleTextSearch} // ì—”í„°í‚¤ë¡œ ê²€ìƒ‰
          editable={!isSearching && !isListening}
        />
        <TouchableOpacity onPress={handleTextSearch} disabled={isSearching || isListening}>
          <Ionicons name="search" size={18} color="#FF5900" />
        </TouchableOpacity>
      </View>

      <View style={styles.guideTextContainer}>
        <Text style={styles.guideText}>
          {isSearching ? 'ê²€ìƒ‰ ì¤‘...' : 'ë§ˆì´í¬ë¥¼ ëˆ„ë¥´ê³  ëª©ì ì§€ë¥¼ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.'}
        </Text>
        <Text style={styles.exampleText}>ì˜ˆ) "ì„œìš¸ì—­ê¹Œì§€ ê°€ê³  ì‹¶ì–´"</Text>
      </View>

      {/* ë§ˆì´í¬ ë²„íŠ¼ */}
      <View style={styles.centerContent}>
        <TouchableOpacity
          style={[
            styles.micButton,
            (isListening || isSearching) && styles.micButtonActive
          ]}
          onPress={isListening ? stopRecognizing : startRecognizing}
          disabled={isSearching}
        >
          {isSearching ? (
            <Ionicons name="hourglass-outline" size={100} color="white" />
          ) : (
            <Ionicons name="mic-outline" size={100} color="white" />
          )}
        </TouchableOpacity>
      </View>

      {/* ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì‹¤ì‹œê°„ ì¶œë ¥ */}
      <View style={styles.resultContainer}>
        <Text style={styles.resultTitle}>ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸</Text>
        <Text style={styles.resultText}>
          {isSearching
            ? 'ê²€ìƒ‰ ì¤‘...'
            : recognizedText || 'ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”.'
          }
        </Text>
      </View>

      {/* ë¡œê·¸ ì¶œë ¥ */}
      <ScrollView style={styles.logContainer}>
        {logMessages.map((msg, idx) => (
          <Text key={idx} style={styles.logText}>â€¢ {msg}</Text>
        ))}
      </ScrollView>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#fff',
    paddingTop: 50,
  },
  searchBox: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: '#FFEFE5',
    paddingHorizontal: 15,
    paddingVertical: 8,
    borderRadius: 20,
    width: '80%',
    height: '12%',
    alignSelf: 'center',
    marginBottom: 20,
  },
  input: {
    flex: 1,
    fontSize: 20,
    color: '#FF5900',
  },
  guideTextContainer: {
    marginTop: 50,
    marginBottom: 30,
    alignItems: 'center',
  },
  guideText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
    marginBottom: 4,
  },
  exampleText: {
    fontSize: 20,
    color: '#444',
    textAlign: 'center',
  },
  centerContent: {
    alignItems: 'center',
    justifyContent: 'center',
  },
  micButton: {
    backgroundColor: '#FF5900',
    width: 200,
    height: 200,
    borderRadius: 100,
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOpacity: 0.15,
    shadowRadius: 6,
    shadowOffset: { width: 0, height: 3 },
  },
  micButtonActive: {
    shadowColor: '#FF5900',
    shadowOpacity: 0.6,
    shadowRadius: 25,
    shadowOffset: { width: 0, height: 0 },
    elevation: 20,
  },
  resultContainer: {
    paddingHorizontal: 30,
    paddingTop: 40,
  },
  resultTitle: {
    fontSize: 16,
    color: '#666',
    marginBottom: 8,
  },
  resultText: {
    fontSize: 20,
    color: '#000',
    textAlign: 'center',
  },
  logContainer: {
    maxHeight: 150,
    paddingHorizontal: 20,
    marginTop: 30,
    marginBottom: 20,
  },
  logText: {
    fontSize: 14,
    color: '#333',
    marginBottom: 4,
  },
});